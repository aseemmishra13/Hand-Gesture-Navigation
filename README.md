This repository implements a hand gesture based navigation system that leverages deep learning for real-time gesture recognition. 
By translating detected hand gestures into keyboard commands using the PyAutoGUI library, the system enables touchless control for various applications such as scrolling, pausing media, toggling full screen, and more.

How to Run:

Clone the git
Run the  cell in DeepLearningRecordingAndDetection.ipynb

These 11 classes represent different hand gestures that we use in our project
like 'fingerup', 'fingerdown', 'thumbsup', 'thumbsdown', 'fingerleft', 'fingerright', 'ok', 'closedfist', 'peace sign', 'rockon sign', 'L'.

